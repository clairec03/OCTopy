{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/SimCLR/blob/simclr-refactor/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YUemQib7ZE4D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BfIPl0G6_RrT"
      },
      "outputs": [],
      "source": [
        "# normalize = [(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)]\n",
        "normalize = [(0.12, 0.12, 0.12), (0.19, 0.19, 0.19)]\n",
        "\n",
        "def get_oct_test_simclr_pipeline_transform():\n",
        "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
        "    data_transforms = transforms.Compose(\n",
        "        [\n",
        "            # transforms.Resize(size=(224, 224)),\n",
        "            transforms.Resize(size=(256, 256)),\n",
        "            transforms.RandomResizedCrop(size=224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(*normalize),\n",
        "        ]\n",
        "    )\n",
        "    return data_transforms\n",
        "\n",
        "\n",
        "def get_oct_simclr_pipeline_transform():\n",
        "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
        "    color_jitter = transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
        "    data_transforms = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.RandomResizedCrop(size=224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomApply([color_jitter], p=0.8),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(*normalize),\n",
        "        ]\n",
        "    )\n",
        "    return data_transforms\n",
        "\n",
        "\n",
        "def get_oct_data_loaders(root_path, batch_size=32):\n",
        "    train_dataset = datasets.ImageFolder(f\"{root_path}/train\", transform=get_oct_simclr_pipeline_transform())\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, drop_last=False, shuffle=True)\n",
        "\n",
        "    test_dataset = datasets.ImageFolder(f\"{root_path}/test\", transform=get_oct_test_simclr_pipeline_transform())\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=8, drop_last=False, shuffle=True)\n",
        "\n",
        "    val_dataset = datasets.ImageFolder(f\"{root_path}/val\", transform=get_oct_test_simclr_pipeline_transform())\n",
        "\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=8, drop_last=False, shuffle=True)\n",
        "    return train_loader, test_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "6N8lYkbmDTaK"
      },
      "outputs": [],
      "source": [
        "with open(\"./config.yml\") as file:\n",
        "    config = yaml.load(file, Loader=yaml.UnsafeLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "a18lPD-tIle6"
      },
      "outputs": [],
      "source": [
        "if config.arch == \"resnet18\":\n",
        "    model = torchvision.models.resnet18(pretrained=False, num_classes=4).to(device)\n",
        "elif config.arch == \"resnet50\":\n",
        "    model = torchvision.models.resnet50(pretrained=False, num_classes=4).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4AIfgq41GuTT"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(config.checkpoint_path, map_location=device)\n",
        "state_dict = checkpoint[\"state_dict\"]\n",
        "\n",
        "for k in list(state_dict.keys()):\n",
        "    if k.startswith(\"backbone.\"):\n",
        "        if k.startswith(\"backbone\") and not k.startswith(\"backbone.fc\"):\n",
        "            # remove prefix\n",
        "            state_dict[k[len(\"backbone.\") :]] = state_dict[k]\n",
        "    del state_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "VVjA83PPJYWl"
      },
      "outputs": [],
      "source": [
        "log = model.load_state_dict(state_dict, strict=False)\n",
        "assert log.missing_keys == ['fc.weight', 'fc.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "149b9ce8fb68473a837a77431c12281a",
            "88cd3db2831e4c13a4a634709700d6b2",
            "a88c31d74f5c40a2b24bcff5a35d216c",
            "60c6150177694717a622936b830427b5",
            "dba019efadee4fdc8c799f309b9a7e70",
            "5901c2829a554c8ebbd5926610088041",
            "957362a11d174407979cf17012bf9208",
            "a4f82234388e4701a02a9f68a177193a"
          ]
        },
        "id": "_GC0a14uWRr6",
        "outputId": "4c2558db-921c-425e-f947-6cc746d8c749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: oct\n"
          ]
        }
      ],
      "source": [
        "if config.dataset_name == \"oct\":\n",
        "    train_loader, test_loader, val_loader = get_oct_data_loaders(config.dataset_path, config.batch_size)\n",
        "print(\"Dataset:\", config.dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "pYT_KsM0Mnnr"
      },
      "outputs": [],
      "source": [
        "# freeze all layers but the last fc\n",
        "for name, param in model.named_parameters():\n",
        "    if name not in ['fc.weight', 'fc.bias']:\n",
        "        param.requires_grad = False\n",
        "\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "assert len(parameters) == 2  # fc.weight, fc.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "aPVh1S_eMRDU"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.0008)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "edr6RhP2PdVq"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOder0dAMI7X",
        "outputId": "5f723b91-5a5e-43eb-ca01-a9b5ae2f1346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, train_loss: 1.4383950630823772, train_acc: 26.767676035563152, test_acc: 34.693878173828125, val_acc: 45.238094329833984\n",
            "Epoch: 1, train_loss: 1.3258229494094849, train_acc: 39.47811381022135, test_acc: 42.85714340209961, val_acc: 42.85714340209961\n",
            "Epoch: 2, train_loss: 1.229421893755595, train_acc: 43.07922871907552, test_acc: 44.89795684814453, val_acc: 42.85714340209961\n",
            "Epoch: 3, train_loss: 1.1917271216710408, train_acc: 48.4217160542806, test_acc: 38.775508880615234, val_acc: 42.85714340209961\n",
            "Epoch: 4, train_loss: 1.147494951883952, train_acc: 49.60279846191406, test_acc: 44.89795684814453, val_acc: 40.47618865966797\n",
            "Epoch: 5, train_loss: 1.1102863152821858, train_acc: 53.70633316040039, test_acc: 53.06122589111328, val_acc: 38.095237731933594\n",
            "Epoch: 6, train_loss: 1.0957211256027222, train_acc: 52.372684478759766, test_acc: 40.81632614135742, val_acc: 47.619049072265625\n",
            "Epoch: 7, train_loss: 1.0877915223439534, train_acc: 52.13068135579427, test_acc: 34.693878173828125, val_acc: 42.85714340209961\n",
            "Epoch: 8, train_loss: 1.0356387495994568, train_acc: 55.91066869099935, test_acc: 48.979591369628906, val_acc: 45.238094329833984\n",
            "Epoch: 9, train_loss: 1.0372981230417888, train_acc: 53.97990163167318, test_acc: 40.81632614135742, val_acc: 45.238094329833984\n",
            "Epoch: 10, train_loss: 1.0370738506317139, train_acc: 57.383731842041016, test_acc: 53.06122589111328, val_acc: 42.85714340209961\n",
            "Epoch: 11, train_loss: 1.0329328179359436, train_acc: 56.53935114542643, test_acc: 55.1020393371582, val_acc: 42.85714340209961\n",
            "Epoch: 12, train_loss: 0.9953168829282125, train_acc: 57.18118540445963, test_acc: 48.979591369628906, val_acc: 47.619049072265625\n",
            "Epoch: 13, train_loss: 1.0077905257542927, train_acc: 55.96064758300781, test_acc: 48.979591369628906, val_acc: 50.0\n",
            "Epoch: 14, train_loss: 0.9934838612874349, train_acc: 60.153619130452476, test_acc: 48.979591369628906, val_acc: 45.238094329833984\n",
            "Epoch: 15, train_loss: 0.9861095547676086, train_acc: 57.872999827067055, test_acc: 38.775508880615234, val_acc: 40.47618865966797\n",
            "Epoch: 16, train_loss: 0.9991332292556763, train_acc: 57.51788584391276, test_acc: 61.2244873046875, val_acc: 47.619049072265625\n",
            "Epoch: 17, train_loss: 1.0003720720609028, train_acc: 57.96243540445963, test_acc: 55.1020393371582, val_acc: 52.380950927734375\n",
            "Epoch: 18, train_loss: 0.9872100353240967, train_acc: 58.40698496500651, test_acc: 53.06122589111328, val_acc: 42.85714340209961\n",
            "Epoch: 19, train_loss: 0.9935715198516846, train_acc: 57.549452463785805, test_acc: 46.93877410888672, val_acc: 42.85714340209961\n",
            "Epoch: 20, train_loss: 0.9955323338508606, train_acc: 56.12636693318685, test_acc: 55.1020393371582, val_acc: 45.238094329833984\n",
            "Epoch: 21, train_loss: 0.9879926244417826, train_acc: 57.47316869099935, test_acc: 46.93877410888672, val_acc: 42.85714340209961\n",
            "Epoch: 22, train_loss: 0.9696646928787231, train_acc: 60.566602071126304, test_acc: 44.89795684814453, val_acc: 35.71428680419922\n",
            "Epoch: 23, train_loss: 0.9657507737477621, train_acc: 59.219801584879555, test_acc: 46.93877410888672, val_acc: 42.85714340209961\n",
            "Epoch: 24, train_loss: 0.9536901513735453, train_acc: 61.01115163167318, test_acc: 48.979591369628906, val_acc: 47.619049072265625\n",
            "Epoch: 25, train_loss: 0.9818465312321981, train_acc: 56.61563491821289, test_acc: 53.06122589111328, val_acc: 50.0\n",
            "Epoch: 26, train_loss: 0.9620861013730367, train_acc: 60.52188491821289, test_acc: 48.979591369628906, val_acc: 42.85714340209961\n",
            "Epoch: 27, train_loss: 0.9539519349733988, train_acc: 60.33775202433268, test_acc: 48.979591369628906, val_acc: 45.238094329833984\n",
            "Epoch: 28, train_loss: 0.9500694672266642, train_acc: 60.674452463785805, test_acc: 55.1020393371582, val_acc: 50.0\n",
            "Epoch: 29, train_loss: 0.9401239554087321, train_acc: 62.694653828938804, test_acc: 51.020408630371094, val_acc: 45.238094329833984\n",
            "Epoch: 30, train_loss: 0.9677396814028422, train_acc: 59.65119934082031, test_acc: 51.020408630371094, val_acc: 45.238094329833984\n",
            "Epoch: 31, train_loss: 0.9596288998921713, train_acc: 60.62973403930664, test_acc: 51.020408630371094, val_acc: 42.85714340209961\n",
            "Epoch: 32, train_loss: 0.943180501461029, train_acc: 62.57365163167318, test_acc: 48.979591369628906, val_acc: 45.238094329833984\n",
            "Epoch: 33, train_loss: 0.9441354274749756, train_acc: 59.77220026652018, test_acc: 46.93877410888672, val_acc: 45.238094329833984\n",
            "Epoch: 34, train_loss: 0.9459706544876099, train_acc: 59.96948496500651, test_acc: 48.979591369628906, val_acc: 38.095237731933594\n",
            "Epoch: 35, train_loss: 0.9478335976600647, train_acc: 61.671400705973305, test_acc: 46.93877410888672, val_acc: 38.095237731933594\n",
            "Epoch: 36, train_loss: 0.9460421800613403, train_acc: 61.024304707845054, test_acc: 46.93877410888672, val_acc: 47.619049072265625\n",
            "Epoch: 37, train_loss: 0.939506451288859, train_acc: 58.241265614827476, test_acc: 48.979591369628906, val_acc: 52.380950927734375\n",
            "Epoch: 38, train_loss: 0.9216431776682535, train_acc: 61.913403828938804, test_acc: 55.1020393371582, val_acc: 40.47618865966797\n",
            "Epoch: 39, train_loss: 0.9278712670008341, train_acc: 65.08312225341797, test_acc: 55.1020393371582, val_acc: 50.0\n",
            "Epoch: 40, train_loss: 0.9193313121795654, train_acc: 63.507469177246094, test_acc: 51.020408630371094, val_acc: 54.761905670166016\n",
            "Epoch: 41, train_loss: 0.9325652519861857, train_acc: 59.296085357666016, test_acc: 42.85714340209961, val_acc: 57.14285659790039\n",
            "Epoch: 42, train_loss: 0.926966150601705, train_acc: 61.53198496500651, test_acc: 53.06122589111328, val_acc: 52.380950927734375\n",
            "Epoch: 43, train_loss: 0.9573232134183248, train_acc: 58.77525202433268, test_acc: 55.1020393371582, val_acc: 45.238094329833984\n",
            "Epoch: 44, train_loss: 0.9453895092010498, train_acc: 60.22990163167318, test_acc: 55.1020393371582, val_acc: 38.095237731933594\n",
            "Epoch: 45, train_loss: 0.9432884852091471, train_acc: 58.37541961669922, test_acc: 51.020408630371094, val_acc: 33.33333206176758\n",
            "Epoch: 46, train_loss: 0.9218973716100057, train_acc: 60.566602071126304, test_acc: 53.06122589111328, val_acc: 57.14285659790039\n",
            "Epoch: 47, train_loss: 0.9260052045186361, train_acc: 61.132153828938804, test_acc: 48.979591369628906, val_acc: 38.095237731933594\n",
            "Epoch: 48, train_loss: 0.948921263217926, train_acc: 60.87173716227213, test_acc: 51.020408630371094, val_acc: 50.0\n",
            "Epoch: 49, train_loss: 0.9207197427749634, train_acc: 63.933606465657554, test_acc: 44.89795684814453, val_acc: 47.619049072265625\n",
            "Epoch: 50, train_loss: 0.934656580289205, train_acc: 60.153619130452476, test_acc: 46.93877410888672, val_acc: 47.619049072265625\n",
            "Epoch: 51, train_loss: 0.9421920975049337, train_acc: 61.944969177246094, test_acc: 55.1020393371582, val_acc: 50.0\n",
            "Epoch: 52, train_loss: 0.9263918995857239, train_acc: 63.76788584391276, test_acc: 55.1020393371582, val_acc: 45.238094329833984\n",
            "Epoch: 53, train_loss: 0.92755655447642, train_acc: 63.475903828938804, test_acc: 48.979591369628906, val_acc: 42.85714340209961\n",
            "Epoch: 54, train_loss: 0.9110112388928732, train_acc: 61.08743540445963, test_acc: 53.06122589111328, val_acc: 42.85714340209961\n",
            "Epoch: 55, train_loss: 0.9221072991689047, train_acc: 61.60826873779297, test_acc: 53.06122589111328, val_acc: 38.095237731933594\n",
            "Epoch: 56, train_loss: 0.9342376788457235, train_acc: 64.88583628336589, test_acc: 48.979591369628906, val_acc: 35.71428680419922\n",
            "Epoch: 57, train_loss: 0.9167638818422953, train_acc: 59.511783599853516, test_acc: 55.1020393371582, val_acc: 47.619049072265625\n",
            "Epoch: 58, train_loss: 0.903084397315979, train_acc: 64.32028579711914, test_acc: 53.06122589111328, val_acc: 35.71428680419922\n",
            "Epoch: 59, train_loss: 0.8965115348498026, train_acc: 63.52062225341797, test_acc: 48.979591369628906, val_acc: 57.14285659790039\n",
            "Epoch: 60, train_loss: 0.8988137443860372, train_acc: 63.13920338948568, test_acc: 55.1020393371582, val_acc: 45.238094329833984\n",
            "Epoch: 61, train_loss: 0.8756853739420573, train_acc: 66.42992401123047, test_acc: 51.020408630371094, val_acc: 47.619049072265625\n",
            "Epoch: 62, train_loss: 0.9602896571159363, train_acc: 59.90635426839193, test_acc: 51.020408630371094, val_acc: 57.14285659790039\n",
            "Epoch: 63, train_loss: 0.9616903265317281, train_acc: 60.33775202433268, test_acc: 55.1020393371582, val_acc: 57.14285659790039\n",
            "Epoch: 64, train_loss: 0.9101622700691223, train_acc: 62.421085357666016, test_acc: 55.1020393371582, val_acc: 54.761905670166016\n",
            "Epoch: 65, train_loss: 0.8953603704770406, train_acc: 63.35490163167318, test_acc: 57.14285659790039, val_acc: 47.619049072265625\n",
            "Epoch: 66, train_loss: 0.9135939478874207, train_acc: 60.79545338948568, test_acc: 61.2244873046875, val_acc: 50.0\n",
            "Epoch: 67, train_loss: 0.9049918254216512, train_acc: 63.507469177246094, test_acc: 44.89795684814453, val_acc: 52.380950927734375\n",
            "Epoch: 68, train_loss: 0.9119379719098409, train_acc: 61.671400705973305, test_acc: 40.81632614135742, val_acc: 52.380950927734375\n",
            "Epoch: 69, train_loss: 0.8761473099390665, train_acc: 66.15635426839192, test_acc: 59.18367385864258, val_acc: 35.71428680419922\n",
            "Epoch: 70, train_loss: 0.9246196349461874, train_acc: 59.893202463785805, test_acc: 55.1020393371582, val_acc: 54.761905670166016\n",
            "Epoch: 71, train_loss: 0.911949078241984, train_acc: 62.344801584879555, test_acc: 46.93877410888672, val_acc: 45.238094329833984\n",
            "Epoch: 72, train_loss: 0.9150249560674032, train_acc: 64.21243540445964, test_acc: 46.93877410888672, val_acc: 45.238094329833984\n",
            "Epoch: 73, train_loss: 0.923009435335795, train_acc: 60.66129938761393, test_acc: 51.020408630371094, val_acc: 47.619049072265625\n",
            "Epoch: 74, train_loss: 0.9304740826288859, train_acc: 61.563551584879555, test_acc: 63.26530456542969, val_acc: 47.619049072265625\n",
            "Epoch: 75, train_loss: 0.867499053478241, train_acc: 67.77672322591145, test_acc: 46.93877410888672, val_acc: 42.85714340209961\n",
            "Epoch: 76, train_loss: 0.9365678826967875, train_acc: 61.639835357666016, test_acc: 46.93877410888672, val_acc: 47.619049072265625\n",
            "Epoch: 77, train_loss: 0.9093962907791138, train_acc: 62.64993540445963, test_acc: 51.020408630371094, val_acc: 47.619049072265625\n",
            "Epoch: 78, train_loss: 0.896195113658905, train_acc: 65.22253672281902, test_acc: 55.1020393371582, val_acc: 42.85714340209961\n",
            "Epoch: 79, train_loss: 0.901707390944163, train_acc: 62.910352071126304, test_acc: 46.93877410888672, val_acc: 50.0\n",
            "Epoch: 80, train_loss: 0.9123566945393881, train_acc: 63.70475514729818, test_acc: 67.34693908691406, val_acc: 50.0\n",
            "Epoch: 81, train_loss: 0.9094667832056681, train_acc: 61.31628672281901, test_acc: 48.979591369628906, val_acc: 50.0\n",
            "Epoch: 82, train_loss: 0.8610193928082784, train_acc: 64.8227055867513, test_acc: 51.020408630371094, val_acc: 50.0\n",
            "Epoch: 83, train_loss: 0.9304757515589396, train_acc: 61.240002950032554, test_acc: 53.06122589111328, val_acc: 50.0\n",
            "Epoch: 84, train_loss: 0.9191375970840454, train_acc: 61.68455251057943, test_acc: 44.89795684814453, val_acc: 47.619049072265625\n",
            "Epoch: 85, train_loss: 0.9062020579973856, train_acc: 63.152356465657554, test_acc: 51.020408630371094, val_acc: 54.761905670166016\n",
            "Epoch: 86, train_loss: 0.9047843416531881, train_acc: 63.13920338948568, test_acc: 57.14285659790039, val_acc: 59.523807525634766\n",
            "Epoch: 87, train_loss: 0.8974679509798685, train_acc: 60.61132049560547, test_acc: 44.89795684814453, val_acc: 54.761905670166016\n",
            "Epoch: 88, train_loss: 0.8550413250923157, train_acc: 67.7320073445638, test_acc: 46.93877410888672, val_acc: 54.761905670166016\n",
            "Epoch: 89, train_loss: 0.9273989796638489, train_acc: 61.57670338948568, test_acc: 55.1020393371582, val_acc: 50.0\n",
            "Epoch: 90, train_loss: 0.9148517648379008, train_acc: 64.39656829833984, test_acc: 48.979591369628906, val_acc: 54.761905670166016\n",
            "Epoch: 91, train_loss: 0.9085859656333923, train_acc: 62.03440602620443, test_acc: 46.93877410888672, val_acc: 54.761905670166016\n",
            "Epoch: 92, train_loss: 0.8841960231463114, train_acc: 64.80955251057942, test_acc: 57.14285659790039, val_acc: 47.619049072265625\n",
            "Epoch: 93, train_loss: 0.8953131437301636, train_acc: 64.99368540445964, test_acc: 51.020408630371094, val_acc: 52.380950927734375\n",
            "Epoch: 94, train_loss: 0.8662065664927164, train_acc: 63.507469177246094, test_acc: 44.89795684814453, val_acc: 50.0\n",
            "Epoch: 95, train_loss: 0.8742209474245707, train_acc: 65.10153579711914, test_acc: 53.06122589111328, val_acc: 50.0\n",
            "Epoch: 96, train_loss: 0.8959883054097494, train_acc: 61.240002950032554, test_acc: 51.020408630371094, val_acc: 50.0\n",
            "Epoch: 97, train_loss: 0.8537317315737406, train_acc: 65.19097137451172, test_acc: 59.18367385864258, val_acc: 52.380950927734375\n",
            "Epoch: 98, train_loss: 0.917537530263265, train_acc: 63.615318298339844, test_acc: 51.020408630371094, val_acc: 54.761905670166016\n",
            "Epoch: 99, train_loss: 0.895871639251709, train_acc: 61.271568298339844, test_acc: 57.14285659790039, val_acc: 57.14285659790039\n"
          ]
        }
      ],
      "source": [
        "train_loss_arr, train_acc_arr, test_acc_arr, val_acc_arr = [], [], [], []\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    top1_train_accuracy = 0\n",
        "    train_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        logits = model(x_batch)\n",
        "        loss = criterion(logits, y_batch)\n",
        "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "        top1_train_accuracy += top1[0].item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss_arr.append(train_loss / len(train_loader))\n",
        "    train_acc_arr.append(top1_train_accuracy / len(train_loader))\n",
        "\n",
        "\n",
        "    top1_accuracy = 0\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        logits = model(x_batch)\n",
        "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "        top1_accuracy += top1[0].item()\n",
        "    test_acc_arr.append(top1_accuracy / len(test_loader))\n",
        "\n",
        "    top1_accuracy = 0\n",
        "    for x_batch, y_batch in val_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        logits = model(x_batch)\n",
        "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "        top1_accuracy += top1[0].item()\n",
        "    val_acc_arr.append(top1_accuracy / len(val_loader))\n",
        "\n",
        "    print(f\"Epoch: {epoch}, train_loss: {train_loss_arr[-1]}, train_acc: {train_acc_arr[-1]}, test_acc: {test_acc_arr[-1]}, val_acc: {val_acc_arr[-1]}\")\n",
        "\n",
        "root_path = \"./csv\"\n",
        "name = config.name\n",
        "if not os.path.exists(root_path):\n",
        "    os.makedirs(root_path)\n",
        "    \n",
        "with open(f\"{root_path}/{name}.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"train_loss\", \"train_acc\", \"test_acc\", \"val_acc\"])\n",
        "    for i in range(len(train_loss_arr)):\n",
        "        writer.writerow([train_loss_arr[i], train_acc_arr[i], test_acc_arr[i], val_acc_arr[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtYqHZirMNZk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "149b9ce8fb68473a837a77431c12281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a88c31d74f5c40a2b24bcff5a35d216c",
              "IPY_MODEL_60c6150177694717a622936b830427b5"
            ],
            "layout": "IPY_MODEL_88cd3db2831e4c13a4a634709700d6b2"
          }
        },
        "5901c2829a554c8ebbd5926610088041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c6150177694717a622936b830427b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f82234388e4701a02a9f68a177193a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_957362a11d174407979cf17012bf9208",
            "value": " 2640404480/? [00:51&lt;00:00, 32685718.58it/s]"
          }
        },
        "88cd3db2831e4c13a4a634709700d6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957362a11d174407979cf17012bf9208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f82234388e4701a02a9f68a177193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88c31d74f5c40a2b24bcff5a35d216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5901c2829a554c8ebbd5926610088041",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dba019efadee4fdc8c799f309b9a7e70",
            "value": 1
          }
        },
        "dba019efadee4fdc8c799f309b9a7e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
