{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/SimCLR/blob/simclr-refactor/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YUemQib7ZE4D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BfIPl0G6_RrT"
      },
      "outputs": [],
      "source": [
        "normalize = [(0.12, 0.12, 0.12), (0.19, 0.19, 0.19)]\n",
        "\n",
        "def get_oct_test_simclr_pipeline_transform():\n",
        "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
        "    data_transforms = transforms.Compose(\n",
        "        [\n",
        "            # transforms.Resize(size=(224, 224)),\n",
        "            transforms.Resize(size=(256, 256)),\n",
        "            transforms.RandomResizedCrop(size=224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(*normalize),\n",
        "        ]\n",
        "    )\n",
        "    return data_transforms\n",
        "\n",
        "\n",
        "def get_oct_simclr_pipeline_transform():\n",
        "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
        "    color_jitter = transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
        "    data_transforms = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.RandomResizedCrop(size=224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomApply([color_jitter], p=0.8),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(*normalize),\n",
        "        ]\n",
        "    )\n",
        "    return data_transforms\n",
        "\n",
        "\n",
        "def get_oct_data_loaders(root_path, batch_size=32):\n",
        "    train_dataset = datasets.ImageFolder(f\"{root_path}/train\", transform=get_oct_simclr_pipeline_transform())\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, drop_last=False, shuffle=True)\n",
        "\n",
        "    test_dataset = datasets.ImageFolder(f\"{root_path}/test\", transform=get_oct_test_simclr_pipeline_transform())\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=8, drop_last=False, shuffle=True)\n",
        "\n",
        "    val_dataset = datasets.ImageFolder(f\"{root_path}/val\", transform=get_oct_test_simclr_pipeline_transform())\n",
        "\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=8, drop_last=False, shuffle=True)\n",
        "    return train_loader, test_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6N8lYkbmDTaK"
      },
      "outputs": [],
      "source": [
        "with open(\"./config.yml\") as file:\n",
        "    config = yaml.load(file, Loader=yaml.UnsafeLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a18lPD-tIle6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sean/miniconda3/envs/ml/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/sean/miniconda3/envs/ml/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "if config.arch == \"resnet18\":\n",
        "    model = torchvision.models.resnet18(pretrained=False, num_classes=4).to(device)\n",
        "elif config.arch == \"resnet50\":\n",
        "    model = torchvision.models.resnet50(pretrained=False, num_classes=4).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4AIfgq41GuTT"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(config.checkpoint_path, map_location=device)\n",
        "state_dict = checkpoint[\"state_dict\"]\n",
        "\n",
        "for k in list(state_dict.keys()):\n",
        "    if k.startswith(\"backbone.\"):\n",
        "        if k.startswith(\"backbone\") and not k.startswith(\"backbone.fc\"):\n",
        "            # remove prefix\n",
        "            state_dict[k[len(\"backbone.\") :]] = state_dict[k]\n",
        "    del state_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State dict contains\n",
            "odict_keys(['backbone.conv1.weight', 'backbone.bn1.weight', 'backbone.bn1.bias', 'backbone.bn1.running_mean', 'backbone.bn1.running_var', 'backbone.bn1.num_batches_tracked', 'backbone.layer1.0.conv1.weight', 'backbone.layer1.0.bn1.weight', 'backbone.layer1.0.bn1.bias', 'backbone.layer1.0.bn1.running_mean', 'backbone.layer1.0.bn1.running_var', 'backbone.layer1.0.bn1.num_batches_tracked', 'backbone.layer1.0.conv2.weight', 'backbone.layer1.0.bn2.weight', 'backbone.layer1.0.bn2.bias', 'backbone.layer1.0.bn2.running_mean', 'backbone.layer1.0.bn2.running_var', 'backbone.layer1.0.bn2.num_batches_tracked', 'backbone.layer1.1.conv1.weight', 'backbone.layer1.1.bn1.weight', 'backbone.layer1.1.bn1.bias', 'backbone.layer1.1.bn1.running_mean', 'backbone.layer1.1.bn1.running_var', 'backbone.layer1.1.bn1.num_batches_tracked', 'backbone.layer1.1.conv2.weight', 'backbone.layer1.1.bn2.weight', 'backbone.layer1.1.bn2.bias', 'backbone.layer1.1.bn2.running_mean', 'backbone.layer1.1.bn2.running_var', 'backbone.layer1.1.bn2.num_batches_tracked', 'backbone.layer2.0.conv1.weight', 'backbone.layer2.0.bn1.weight', 'backbone.layer2.0.bn1.bias', 'backbone.layer2.0.bn1.running_mean', 'backbone.layer2.0.bn1.running_var', 'backbone.layer2.0.bn1.num_batches_tracked', 'backbone.layer2.0.conv2.weight', 'backbone.layer2.0.bn2.weight', 'backbone.layer2.0.bn2.bias', 'backbone.layer2.0.bn2.running_mean', 'backbone.layer2.0.bn2.running_var', 'backbone.layer2.0.bn2.num_batches_tracked', 'backbone.layer2.0.downsample.0.weight', 'backbone.layer2.0.downsample.1.weight', 'backbone.layer2.0.downsample.1.bias', 'backbone.layer2.0.downsample.1.running_mean', 'backbone.layer2.0.downsample.1.running_var', 'backbone.layer2.0.downsample.1.num_batches_tracked', 'backbone.layer2.1.conv1.weight', 'backbone.layer2.1.bn1.weight', 'backbone.layer2.1.bn1.bias', 'backbone.layer2.1.bn1.running_mean', 'backbone.layer2.1.bn1.running_var', 'backbone.layer2.1.bn1.num_batches_tracked', 'backbone.layer2.1.conv2.weight', 'backbone.layer2.1.bn2.weight', 'backbone.layer2.1.bn2.bias', 'backbone.layer2.1.bn2.running_mean', 'backbone.layer2.1.bn2.running_var', 'backbone.layer2.1.bn2.num_batches_tracked', 'backbone.layer3.0.conv1.weight', 'backbone.layer3.0.bn1.weight', 'backbone.layer3.0.bn1.bias', 'backbone.layer3.0.bn1.running_mean', 'backbone.layer3.0.bn1.running_var', 'backbone.layer3.0.bn1.num_batches_tracked', 'backbone.layer3.0.conv2.weight', 'backbone.layer3.0.bn2.weight', 'backbone.layer3.0.bn2.bias', 'backbone.layer3.0.bn2.running_mean', 'backbone.layer3.0.bn2.running_var', 'backbone.layer3.0.bn2.num_batches_tracked', 'backbone.layer3.0.downsample.0.weight', 'backbone.layer3.0.downsample.1.weight', 'backbone.layer3.0.downsample.1.bias', 'backbone.layer3.0.downsample.1.running_mean', 'backbone.layer3.0.downsample.1.running_var', 'backbone.layer3.0.downsample.1.num_batches_tracked', 'backbone.layer3.1.conv1.weight', 'backbone.layer3.1.bn1.weight', 'backbone.layer3.1.bn1.bias', 'backbone.layer3.1.bn1.running_mean', 'backbone.layer3.1.bn1.running_var', 'backbone.layer3.1.bn1.num_batches_tracked', 'backbone.layer3.1.conv2.weight', 'backbone.layer3.1.bn2.weight', 'backbone.layer3.1.bn2.bias', 'backbone.layer3.1.bn2.running_mean', 'backbone.layer3.1.bn2.running_var', 'backbone.layer3.1.bn2.num_batches_tracked', 'backbone.layer4.0.conv1.weight', 'backbone.layer4.0.bn1.weight', 'backbone.layer4.0.bn1.bias', 'backbone.layer4.0.bn1.running_mean', 'backbone.layer4.0.bn1.running_var', 'backbone.layer4.0.bn1.num_batches_tracked', 'backbone.layer4.0.conv2.weight', 'backbone.layer4.0.bn2.weight', 'backbone.layer4.0.bn2.bias', 'backbone.layer4.0.bn2.running_mean', 'backbone.layer4.0.bn2.running_var', 'backbone.layer4.0.bn2.num_batches_tracked', 'backbone.layer4.0.downsample.0.weight', 'backbone.layer4.0.downsample.1.weight', 'backbone.layer4.0.downsample.1.bias', 'backbone.layer4.0.downsample.1.running_mean', 'backbone.layer4.0.downsample.1.running_var', 'backbone.layer4.0.downsample.1.num_batches_tracked', 'backbone.layer4.1.conv1.weight', 'backbone.layer4.1.bn1.weight', 'backbone.layer4.1.bn1.bias', 'backbone.layer4.1.bn1.running_mean', 'backbone.layer4.1.bn1.running_var', 'backbone.layer4.1.bn1.num_batches_tracked', 'backbone.layer4.1.conv2.weight', 'backbone.layer4.1.bn2.weight', 'backbone.layer4.1.bn2.bias', 'backbone.layer4.1.bn2.running_mean', 'backbone.layer4.1.bn2.running_var', 'backbone.layer4.1.bn2.num_batches_tracked', 'backbone.fc.0.weight', 'backbone.fc.0.bias', 'backbone.fc.2.weight', 'backbone.fc.2.bias'])\n"
          ]
        }
      ],
      "source": [
        "checkpoint = torch.load(config.checkpoint_path, map_location=device)\n",
        "state_dict = checkpoint[\"state_dict\"]\n",
        "print(\"State dict contains\")\n",
        "print(state_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VVjA83PPJYWl"
      },
      "outputs": [],
      "source": [
        "log = model.load_state_dict(state_dict, strict=False)\n",
        "assert log.missing_keys == ['fc.weight', 'fc.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "149b9ce8fb68473a837a77431c12281a",
            "88cd3db2831e4c13a4a634709700d6b2",
            "a88c31d74f5c40a2b24bcff5a35d216c",
            "60c6150177694717a622936b830427b5",
            "dba019efadee4fdc8c799f309b9a7e70",
            "5901c2829a554c8ebbd5926610088041",
            "957362a11d174407979cf17012bf9208",
            "a4f82234388e4701a02a9f68a177193a"
          ]
        },
        "id": "_GC0a14uWRr6",
        "outputId": "4c2558db-921c-425e-f947-6cc746d8c749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: oct\n"
          ]
        }
      ],
      "source": [
        "if config.dataset_name == \"oct\":\n",
        "    train_loader, test_loader, val_loader = get_oct_data_loaders(config.dataset_path, config.batch_size)\n",
        "print(\"Dataset:\", config.dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pYT_KsM0Mnnr"
      },
      "outputs": [],
      "source": [
        "# freeze all layers but the last fc\n",
        "for name, param in model.named_parameters():\n",
        "    if name not in ['fc.weight', 'fc.bias']:\n",
        "        param.requires_grad = False\n",
        "\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "assert len(parameters) == 2  # fc.weight, fc.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aPVh1S_eMRDU"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.0008)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "edr6RhP2PdVq"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /home/sean/miniconda3/envs/ml/lib/python3.11/site-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                    [-1, 4]           2,052\n",
            "================================================================\n",
            "Total params: 11,178,564\n",
            "Trainable params: 2,052\n",
            "Non-trainable params: 11,176,512\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 106.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(model, (3, 224, 224))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOder0dAMI7X",
        "outputId": "5f723b91-5a5e-43eb-ca01-a9b5ae2f1346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, train_loss: 1.3813472986221313, train_acc: 32.509995778401695, test_acc: 34.693878173828125, val_acc: 50.0\n",
            "Epoch: 1, train_loss: 1.336099664370219, train_acc: 39.21769714355469, test_acc: 51.020408630371094, val_acc: 40.47618865966797\n",
            "Epoch: 2, train_loss: 1.3158135016759236, train_acc: 38.43644714355469, test_acc: 48.979591369628906, val_acc: 40.47618865966797\n",
            "Epoch: 3, train_loss: 1.2785048882166545, train_acc: 44.24189758300781, test_acc: 44.89795684814453, val_acc: 42.85714340209961\n",
            "Epoch: 4, train_loss: 1.2590995629628499, train_acc: 43.3080800374349, test_acc: 51.020408630371094, val_acc: 38.095237731933594\n",
            "Epoch: 5, train_loss: 1.237030307451884, train_acc: 43.75262959798177, test_acc: 42.85714340209961, val_acc: 40.47618865966797\n",
            "Epoch: 6, train_loss: 1.2180606126785278, train_acc: 49.12668228149414, test_acc: 48.979591369628906, val_acc: 42.85714340209961\n",
            "Epoch: 7, train_loss: 1.1948458751042683, train_acc: 50.50504938761393, test_acc: 44.89795684814453, val_acc: 47.619049072265625\n",
            "Epoch: 8, train_loss: 1.1750293572743733, train_acc: 54.50073496500651, test_acc: 51.020408630371094, val_acc: 45.238094329833984\n",
            "Epoch: 9, train_loss: 1.1639315684636433, train_acc: 54.824283599853516, test_acc: 46.93877410888672, val_acc: 45.238094329833984\n",
            "Epoch: 10, train_loss: 1.1686222950617473, train_acc: 52.8935178120931, test_acc: 48.979591369628906, val_acc: 42.85714340209961\n",
            "Epoch: 11, train_loss: 1.151916782061259, train_acc: 53.6747678120931, test_acc: 55.1020393371582, val_acc: 47.619049072265625\n",
            "Epoch: 12, train_loss: 1.13880455493927, train_acc: 54.29029846191406, test_acc: 46.93877410888672, val_acc: 42.85714340209961\n",
            "Epoch: 13, train_loss: 1.1198313236236572, train_acc: 53.338067372639976, test_acc: 46.93877410888672, val_acc: 54.761905670166016\n",
            "Epoch: 14, train_loss: 1.1259310245513916, train_acc: 54.41129938761393, test_acc: 51.020408630371094, val_acc: 50.0\n",
            "Epoch: 15, train_loss: 1.0984569390614827, train_acc: 55.08470026652018, test_acc: 48.979591369628906, val_acc: 47.619049072265625\n",
            "Epoch: 16, train_loss: 1.0872059265772502, train_acc: 55.12941869099935, test_acc: 51.020408630371094, val_acc: 42.85714340209961\n",
            "Epoch: 17, train_loss: 1.0870646635691326, train_acc: 57.352166493733726, test_acc: 57.14285659790039, val_acc: 42.85714340209961\n",
            "Epoch: 18, train_loss: 1.0722561677296956, train_acc: 58.45170338948568, test_acc: 46.93877410888672, val_acc: 50.0\n",
            "Epoch: 19, train_loss: 1.0684483448664348, train_acc: 55.802818298339844, test_acc: 51.020408630371094, val_acc: 47.619049072265625\n",
            "Epoch: 20, train_loss: 1.0614594618479412, train_acc: 58.819969177246094, test_acc: 44.89795684814453, val_acc: 54.761905670166016\n",
            "Epoch: 21, train_loss: 1.0581274429957073, train_acc: 56.88920338948568, test_acc: 44.89795684814453, val_acc: 45.238094329833984\n",
            "Epoch: 22, train_loss: 1.0665303468704224, train_acc: 55.637098948160805, test_acc: 42.85714340209961, val_acc: 52.380950927734375\n",
            "Epoch: 23, train_loss: 1.024462103843689, train_acc: 59.601219177246094, test_acc: 44.89795684814453, val_acc: 47.619049072265625\n",
            "Epoch: 24, train_loss: 1.0483176906903584, train_acc: 58.712120056152344, test_acc: 46.93877410888672, val_acc: 42.85714340209961\n",
            "Epoch: 25, train_loss: 1.0424846013387044, train_acc: 55.66866556803385, test_acc: 57.14285659790039, val_acc: 52.380950927734375\n",
            "Epoch: 26, train_loss: 1.009858767191569, train_acc: 60.71916961669922, test_acc: 53.06122589111328, val_acc: 52.380950927734375\n",
            "Epoch: 27, train_loss: 1.0272712707519531, train_acc: 59.435499827067055, test_acc: 53.06122589111328, val_acc: 45.238094329833984\n",
            "Epoch: 28, train_loss: 1.0181777079900105, train_acc: 56.53935114542643, test_acc: 55.1020393371582, val_acc: 42.85714340209961\n",
            "Epoch: 29, train_loss: 1.0275328954060872, train_acc: 57.872999827067055, test_acc: 44.89795684814453, val_acc: 40.47618865966797\n",
            "Epoch: 30, train_loss: 1.0323839386304219, train_acc: 55.605533599853516, test_acc: 44.89795684814453, val_acc: 50.0\n",
            "Epoch: 31, train_loss: 0.9933380881945292, train_acc: 59.296085357666016, test_acc: 48.979591369628906, val_acc: 52.380950927734375\n",
            "Epoch: 32, train_loss: 1.011931578318278, train_acc: 55.75810114542643, test_acc: 48.979591369628906, val_acc: 47.619049072265625\n",
            "Epoch: 33, train_loss: 1.0025294025739033, train_acc: 59.52493540445963, test_acc: 53.06122589111328, val_acc: 45.238094329833984\n",
            "Epoch: 34, train_loss: 1.0082466999689739, train_acc: 58.66740163167318, test_acc: 48.979591369628906, val_acc: 54.761905670166016\n",
            "Epoch: 35, train_loss: 0.976303239663442, train_acc: 59.52493540445963, test_acc: 55.1020393371582, val_acc: 50.0\n",
            "Epoch: 36, train_loss: 0.9756465355555216, train_acc: 58.86468760172526, test_acc: 53.06122589111328, val_acc: 50.0\n",
            "Epoch: 37, train_loss: 0.9847659269968668, train_acc: 58.698968251546226, test_acc: 57.14285659790039, val_acc: 45.238094329833984\n",
            "Epoch: 38, train_loss: 1.0085444053014119, train_acc: 56.768202463785805, test_acc: 55.1020393371582, val_acc: 50.0\n",
            "Epoch: 39, train_loss: 0.9942094087600708, train_acc: 59.709068298339844, test_acc: 48.979591369628906, val_acc: 42.85714340209961\n",
            "Epoch: 40, train_loss: 0.9710475206375122, train_acc: 60.68760426839193, test_acc: 57.14285659790039, val_acc: 42.85714340209961\n",
            "Epoch: 41, train_loss: 0.9762528340021769, train_acc: 61.51883316040039, test_acc: 48.979591369628906, val_acc: 47.619049072265625\n",
            "Epoch: 42, train_loss: 1.0013055801391602, train_acc: 61.132153828938804, test_acc: 46.93877410888672, val_acc: 52.380950927734375\n",
            "Epoch: 43, train_loss: 0.9811657071113586, train_acc: 59.25136693318685, test_acc: 61.2244873046875, val_acc: 45.238094329833984\n",
            "Epoch: 44, train_loss: 0.9816981752713522, train_acc: 58.622684478759766, test_acc: 51.020408630371094, val_acc: 52.380950927734375\n",
            "Epoch: 45, train_loss: 0.9989435275395712, train_acc: 58.806817372639976, test_acc: 46.93877410888672, val_acc: 47.619049072265625\n",
            "Epoch: 46, train_loss: 0.973809003829956, train_acc: 59.03566869099935, test_acc: 44.89795684814453, val_acc: 52.380950927734375\n",
            "Epoch: 47, train_loss: 0.9638209740320841, train_acc: 57.68886693318685, test_acc: 46.93877410888672, val_acc: 54.761905670166016\n",
            "Epoch: 48, train_loss: 0.9841290513674418, train_acc: 57.980848948160805, test_acc: 48.979591369628906, val_acc: 50.0\n",
            "Epoch: 49, train_loss: 0.980522096157074, train_acc: 59.63278579711914, test_acc: 46.93877410888672, val_acc: 45.238094329833984\n",
            "Epoch: 50, train_loss: 0.9356705149014791, train_acc: 61.25315602620443, test_acc: 51.020408630371094, val_acc: 40.47618865966797\n",
            "Epoch: 51, train_loss: 0.9535665512084961, train_acc: 61.68455251057943, test_acc: 48.979591369628906, val_acc: 50.0\n",
            "Epoch: 52, train_loss: 0.9512864152590433, train_acc: 60.90330251057943, test_acc: 48.979591369628906, val_acc: 45.238094329833984\n",
            "Epoch: 53, train_loss: 0.9542908867200216, train_acc: 60.153619130452476, test_acc: 46.93877410888672, val_acc: 42.85714340209961\n"
          ]
        }
      ],
      "source": [
        "train_loss_arr, train_acc_arr, test_acc_arr, val_acc_arr = [], [], [], []\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    top1_train_accuracy = 0\n",
        "    train_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        logits = model(x_batch)\n",
        "        loss = criterion(logits, y_batch)\n",
        "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "        top1_train_accuracy += top1[0].item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss_arr.append(train_loss / len(train_loader))\n",
        "    train_acc_arr.append(top1_train_accuracy / len(train_loader))\n",
        "\n",
        "\n",
        "    top1_accuracy = 0\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        logits = model(x_batch)\n",
        "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "        top1_accuracy += top1[0].item()\n",
        "    test_acc_arr.append(top1_accuracy / len(test_loader))\n",
        "\n",
        "    top1_accuracy = 0\n",
        "    for x_batch, y_batch in val_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        logits = model(x_batch)\n",
        "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "        top1_accuracy += top1[0].item()\n",
        "    val_acc_arr.append(top1_accuracy / len(val_loader))\n",
        "\n",
        "    print(f\"Epoch: {epoch}, train_loss: {train_loss_arr[-1]}, train_acc: {train_acc_arr[-1]}, test_acc: {test_acc_arr[-1]}, val_acc: {val_acc_arr[-1]}\")\n",
        "\n",
        "root_path = \"./csv\"\n",
        "name = config.name\n",
        "if not os.path.exists(root_path):\n",
        "    os.makedirs(root_path)\n",
        "    \n",
        "with open(f\"{root_path}/{name}.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"train_loss\", \"train_acc\", \"test_acc\", \"val_acc\"])\n",
        "    for i in range(len(train_loss_arr)):\n",
        "        writer.writerow([train_loss_arr[i], train_acc_arr[i], test_acc_arr[i], val_acc_arr[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtYqHZirMNZk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "149b9ce8fb68473a837a77431c12281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a88c31d74f5c40a2b24bcff5a35d216c",
              "IPY_MODEL_60c6150177694717a622936b830427b5"
            ],
            "layout": "IPY_MODEL_88cd3db2831e4c13a4a634709700d6b2"
          }
        },
        "5901c2829a554c8ebbd5926610088041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c6150177694717a622936b830427b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f82234388e4701a02a9f68a177193a",
            "placeholder": "​",
            "style": "IPY_MODEL_957362a11d174407979cf17012bf9208",
            "value": " 2640404480/? [00:51&lt;00:00, 32685718.58it/s]"
          }
        },
        "88cd3db2831e4c13a4a634709700d6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957362a11d174407979cf17012bf9208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f82234388e4701a02a9f68a177193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88c31d74f5c40a2b24bcff5a35d216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5901c2829a554c8ebbd5926610088041",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dba019efadee4fdc8c799f309b9a7e70",
            "value": 1
          }
        },
        "dba019efadee4fdc8c799f309b9a7e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
