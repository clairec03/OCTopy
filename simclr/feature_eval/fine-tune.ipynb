{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/SimCLR/blob/simclr-refactor/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YUemQib7ZE4D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BfIPl0G6_RrT"
      },
      "outputs": [],
      "source": [
        "normalize = [(0.12, 0.12, 0.12), (0.19, 0.19, 0.19)]\n",
        "\n",
        "def get_oct_test_simclr_pipeline_transform():\n",
        "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
        "    data_transforms = transforms.Compose(\n",
        "        [\n",
        "            # transforms.Resize(size=(224, 224)),\n",
        "            transforms.Resize(size=(256, 256)),\n",
        "            transforms.RandomResizedCrop(size=224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(*normalize),\n",
        "        ]\n",
        "    )\n",
        "    return data_transforms\n",
        "\n",
        "\n",
        "def get_oct_simclr_pipeline_transform():\n",
        "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
        "    color_jitter = transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
        "    data_transforms = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.RandomResizedCrop(size=224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomApply([color_jitter], p=0.8),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(*normalize),\n",
        "        ]\n",
        "    )\n",
        "    return data_transforms\n",
        "\n",
        "\n",
        "def get_oct_data_loaders(root_path, batch_size=32):\n",
        "    train_dataset = datasets.ImageFolder(f\"{root_path}/train\", transform=get_oct_simclr_pipeline_transform())\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, drop_last=False, shuffle=True)\n",
        "\n",
        "    test_dataset = datasets.ImageFolder(f\"{root_path}/test\", transform=get_oct_test_simclr_pipeline_transform())\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=8, drop_last=False, shuffle=True)\n",
        "\n",
        "    val_dataset = datasets.ImageFolder(f\"{root_path}/val\", transform=get_oct_test_simclr_pipeline_transform())\n",
        "\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=8, drop_last=False, shuffle=True)\n",
        "    return train_loader, test_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6N8lYkbmDTaK"
      },
      "outputs": [],
      "source": [
        "with open(\"./config.yml\") as file:\n",
        "    config = yaml.load(file, Loader=yaml.UnsafeLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a18lPD-tIle6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sean/miniconda3/envs/ml/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/sean/miniconda3/envs/ml/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "if config.arch == \"resnet18\":\n",
        "    model = torchvision.models.resnet18(pretrained=False, num_classes=4).to(device)\n",
        "elif config.arch == \"resnet50\":\n",
        "    model = torchvision.models.resnet50(pretrained=False, num_classes=4).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4AIfgq41GuTT"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(config.checkpoint_path, map_location=device)\n",
        "state_dict = checkpoint[\"state_dict\"]\n",
        "\n",
        "for k in list(state_dict.keys()):\n",
        "    if k.startswith(\"backbone.\"):\n",
        "        if k.startswith(\"backbone\") and not k.startswith(\"backbone.fc\"):\n",
        "            # remove prefix\n",
        "            state_dict[k[len(\"backbone.\") :]] = state_dict[k]\n",
        "    del state_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VVjA83PPJYWl"
      },
      "outputs": [],
      "source": [
        "log = model.load_state_dict(state_dict, strict=False)\n",
        "assert log.missing_keys == ['fc.weight', 'fc.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "149b9ce8fb68473a837a77431c12281a",
            "88cd3db2831e4c13a4a634709700d6b2",
            "a88c31d74f5c40a2b24bcff5a35d216c",
            "60c6150177694717a622936b830427b5",
            "dba019efadee4fdc8c799f309b9a7e70",
            "5901c2829a554c8ebbd5926610088041",
            "957362a11d174407979cf17012bf9208",
            "a4f82234388e4701a02a9f68a177193a"
          ]
        },
        "id": "_GC0a14uWRr6",
        "outputId": "4c2558db-921c-425e-f947-6cc746d8c749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: oct\n"
          ]
        }
      ],
      "source": [
        "if config.dataset_name == \"oct\":\n",
        "    train_loader, test_loader, val_loader = get_oct_data_loaders(config.dataset_path, config.batch_size)\n",
        "print(\"Dataset:\", config.dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pYT_KsM0Mnnr"
      },
      "outputs": [],
      "source": [
        "# freeze all layers but the last fc\n",
        "for name, param in model.named_parameters():\n",
        "    if name not in ['fc.weight', 'fc.bias']:\n",
        "        param.requires_grad = False\n",
        "\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "assert len(parameters) == 2  # fc.weight, fc.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aPVh1S_eMRDU"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.0008)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "edr6RhP2PdVq"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOder0dAMI7X",
        "outputId": "5f723b91-5a5e-43eb-ca01-a9b5ae2f1346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, train_loss: 1.2510051727294922, train_acc: 37.2737782796224, test_acc: 53.06122589111328, val_acc: 54.761905670166016\n",
            "Epoch: 1, train_loss: 1.1115731398264568, train_acc: 53.293348948160805, test_acc: 48.979591369628906, val_acc: 54.761905670166016\n",
            "Epoch: 2, train_loss: 0.9728243549664816, train_acc: 60.04576873779297, test_acc: 61.2244873046875, val_acc: 54.761905670166016\n",
            "Epoch: 3, train_loss: 0.9035053054491679, train_acc: 61.42413584391276, test_acc: 48.979591369628906, val_acc: 52.380950927734375\n",
            "Epoch: 4, train_loss: 0.8164105614026388, train_acc: 64.74642181396484, test_acc: 42.85714340209961, val_acc: 57.14285659790039\n",
            "Epoch: 5, train_loss: 0.866034468015035, train_acc: 63.33648935953776, test_acc: 51.020408630371094, val_acc: 57.14285659790039\n",
            "Epoch: 6, train_loss: 0.7989506920178732, train_acc: 67.27430470784505, test_acc: 55.1020393371582, val_acc: 57.14285659790039\n",
            "Epoch: 7, train_loss: 0.7580038706461588, train_acc: 67.31902313232422, test_acc: 59.18367385864258, val_acc: 54.761905670166016\n",
            "Epoch: 8, train_loss: 0.70541912317276, train_acc: 70.38088989257812, test_acc: 48.979591369628906, val_acc: 57.14285659790039\n",
            "Epoch: 9, train_loss: 0.7150130867958069, train_acc: 67.18486913045247, test_acc: 61.2244873046875, val_acc: 57.14285659790039\n",
            "Epoch: 10, train_loss: 0.6591644485791525, train_acc: 72.75620778401692, test_acc: 61.2244873046875, val_acc: 54.761905670166016\n",
            "Epoch: 11, train_loss: 0.674888034661611, train_acc: 70.13888804117839, test_acc: 53.06122589111328, val_acc: 54.761905670166016\n",
            "Epoch: 12, train_loss: 0.6642879247665405, train_acc: 71.8539555867513, test_acc: 51.020408630371094, val_acc: 57.14285659790039\n",
            "Epoch: 13, train_loss: 0.6241637070973715, train_acc: 73.93728892008464, test_acc: 51.020408630371094, val_acc: 57.14285659790039\n",
            "Epoch: 14, train_loss: 0.6089440584182739, train_acc: 75.06838989257812, test_acc: 53.06122589111328, val_acc: 54.761905670166016\n",
            "Epoch: 15, train_loss: 0.6231045722961426, train_acc: 74.68697357177734, test_acc: 59.18367385864258, val_acc: 61.904762268066406\n",
            "Epoch: 16, train_loss: 0.5811469356218973, train_acc: 76.52304077148438, test_acc: 61.2244873046875, val_acc: 61.904762268066406\n",
            "Epoch: 17, train_loss: 0.5915955305099487, train_acc: 76.52304077148438, test_acc: 59.18367385864258, val_acc: 57.14285659790039\n",
            "Epoch: 18, train_loss: 0.5168713629245758, train_acc: 79.46390787760417, test_acc: 61.2244873046875, val_acc: 57.14285659790039\n",
            "Epoch: 19, train_loss: 0.4967111547787984, train_acc: 80.06102498372395, test_acc: 51.020408630371094, val_acc: 54.761905670166016\n",
            "Epoch: 20, train_loss: 0.6617652177810669, train_acc: 74.1977055867513, test_acc: 63.26530456542969, val_acc: 54.761905670166016\n",
            "Epoch: 21, train_loss: 0.5608623226483663, train_acc: 75.7602055867513, test_acc: 48.979591369628906, val_acc: 57.14285659790039\n",
            "Epoch: 22, train_loss: 0.616622676452001, train_acc: 75.5445073445638, test_acc: 57.14285659790039, val_acc: 64.28571319580078\n",
            "Epoch: 23, train_loss: 0.6302572091420492, train_acc: 74.53440602620442, test_acc: 59.18367385864258, val_acc: 61.904762268066406\n",
            "Epoch: 24, train_loss: 0.5719103415807089, train_acc: 78.79050699869792, test_acc: 65.30612182617188, val_acc: 52.380950927734375\n",
            "Epoch: 25, train_loss: 0.5508294204870859, train_acc: 77.7041244506836, test_acc: 57.14285659790039, val_acc: 59.523807525634766\n",
            "Epoch: 26, train_loss: 0.5734686652819315, train_acc: 75.5445073445638, test_acc: 61.2244873046875, val_acc: 45.238094329833984\n",
            "Epoch: 27, train_loss: 0.5814075966676077, train_acc: 76.49673716227214, test_acc: 51.020408630371094, val_acc: 52.380950927734375\n",
            "Epoch: 28, train_loss: 0.5315204660097758, train_acc: 77.0438741048177, test_acc: 57.14285659790039, val_acc: 52.380950927734375\n",
            "Epoch: 29, train_loss: 0.5275386969248453, train_acc: 78.57480875651042, test_acc: 55.1020393371582, val_acc: 57.14285659790039\n",
            "Epoch: 30, train_loss: 0.46909740567207336, train_acc: 82.66519165039062, test_acc: 55.1020393371582, val_acc: 61.904762268066406\n",
            "Epoch: 31, train_loss: 0.559512714544932, train_acc: 78.56165822347005, test_acc: 51.020408630371094, val_acc: 64.28571319580078\n",
            "Epoch: 32, train_loss: 0.5162933866182963, train_acc: 79.31134033203125, test_acc: 57.14285659790039, val_acc: 59.523807525634766\n",
            "Epoch: 33, train_loss: 0.542853573958079, train_acc: 78.16182454427083, test_acc: 55.1020393371582, val_acc: 54.761905670166016\n",
            "Epoch: 34, train_loss: 0.5753848354021708, train_acc: 76.63088989257812, test_acc: 53.06122589111328, val_acc: 64.28571319580078\n",
            "Epoch: 35, train_loss: 0.5062408645947775, train_acc: 82.63362630208333, test_acc: 59.18367385864258, val_acc: 57.14285659790039\n",
            "Epoch: 36, train_loss: 0.4974296490351359, train_acc: 83.30702718098958, test_acc: 59.18367385864258, val_acc: 57.14285659790039\n",
            "Epoch: 37, train_loss: 0.47469067573547363, train_acc: 82.3284912109375, test_acc: 53.06122589111328, val_acc: 52.380950927734375\n",
            "Epoch: 38, train_loss: 0.43469440937042236, train_acc: 83.75157674153645, test_acc: 53.06122589111328, val_acc: 52.380950927734375\n",
            "Epoch: 39, train_loss: 0.4421326418717702, train_acc: 80.42929077148438, test_acc: 57.14285659790039, val_acc: 64.28571319580078\n",
            "Epoch: 40, train_loss: 0.5045903424421946, train_acc: 80.65814208984375, test_acc: 59.18367385864258, val_acc: 45.238094329833984\n",
            "Epoch: 41, train_loss: 0.3699783484141032, train_acc: 87.3658447265625, test_acc: 63.26530456542969, val_acc: 61.904762268066406\n",
            "Epoch: 42, train_loss: 0.5069019794464111, train_acc: 79.15877278645833, test_acc: 55.1020393371582, val_acc: 57.14285659790039\n",
            "Epoch: 43, train_loss: 0.3439109226067861, train_acc: 87.7656758626302, test_acc: 61.2244873046875, val_acc: 57.14285659790039\n",
            "Epoch: 44, train_loss: 0.4017696777979533, train_acc: 85.0536600748698, test_acc: 55.1020393371582, val_acc: 59.523807525634766\n",
            "Epoch: 45, train_loss: 0.41672735412915546, train_acc: 83.52272542317708, test_acc: 55.1020393371582, val_acc: 45.238094329833984\n",
            "Epoch: 46, train_loss: 0.48482812444369, train_acc: 80.64499155680339, test_acc: 61.2244873046875, val_acc: 59.523807525634766\n",
            "Epoch: 47, train_loss: 0.4426906208197276, train_acc: 83.26230875651042, test_acc: 55.1020393371582, val_acc: 57.14285659790039\n",
            "Epoch: 48, train_loss: 0.4988219936688741, train_acc: 80.35300699869792, test_acc: 53.06122589111328, val_acc: 50.0\n",
            "Epoch: 49, train_loss: 0.485946387052536, train_acc: 82.43634033203125, test_acc: 48.979591369628906, val_acc: 47.619049072265625\n",
            "Epoch: 50, train_loss: 0.46653681993484497, train_acc: 81.50252278645833, test_acc: 48.979591369628906, val_acc: 59.523807525634766\n",
            "Epoch: 51, train_loss: 0.4417753020922343, train_acc: 80.50557454427083, test_acc: 57.14285659790039, val_acc: 61.904762268066406\n",
            "Epoch: 52, train_loss: 0.36202120780944824, train_acc: 86.6161600748698, test_acc: 59.18367385864258, val_acc: 57.14285659790039\n",
            "Epoch: 53, train_loss: 0.4197281797726949, train_acc: 83.15445963541667, test_acc: 57.14285659790039, val_acc: 50.0\n",
            "Epoch: 54, train_loss: 0.4259950915972392, train_acc: 83.1413065592448, test_acc: 55.1020393371582, val_acc: 61.904762268066406\n",
            "Epoch: 55, train_loss: 0.4882735510667165, train_acc: 79.90845743815105, test_acc: 46.93877410888672, val_acc: 61.904762268066406\n",
            "Epoch: 56, train_loss: 0.39209575454394024, train_acc: 84.53282674153645, test_acc: 59.18367385864258, val_acc: 52.380950927734375\n",
            "Epoch: 57, train_loss: 0.4443473815917969, train_acc: 80.84227498372395, test_acc: 63.26530456542969, val_acc: 59.523807525634766\n",
            "Epoch: 58, train_loss: 0.4428565998872121, train_acc: 82.44949340820312, test_acc: 55.1020393371582, val_acc: 54.761905670166016\n",
            "Epoch: 59, train_loss: 0.47660304109255475, train_acc: 79.29818979899089, test_acc: 61.2244873046875, val_acc: 54.761905670166016\n",
            "Epoch: 60, train_loss: 0.40682127078374225, train_acc: 84.71695963541667, test_acc: 55.1020393371582, val_acc: 52.380950927734375\n",
            "Epoch: 61, train_loss: 0.41888733704884845, train_acc: 83.0781758626302, test_acc: 57.14285659790039, val_acc: 61.904762268066406\n",
            "Epoch: 62, train_loss: 0.4349893033504486, train_acc: 82.34164428710938, test_acc: 53.06122589111328, val_acc: 54.761905670166016\n",
            "Epoch: 63, train_loss: 0.4096136788527171, train_acc: 86.01904296875, test_acc: 55.1020393371582, val_acc: 71.42857360839844\n",
            "Epoch: 64, train_loss: 0.42193488279978436, train_acc: 84.71695963541667, test_acc: 61.2244873046875, val_acc: 66.66666412353516\n",
            "Epoch: 65, train_loss: 0.44989288846651715, train_acc: 81.99179077148438, test_acc: 55.1020393371582, val_acc: 59.523807525634766\n",
            "Epoch: 66, train_loss: 0.3957512378692627, train_acc: 85.9874776204427, test_acc: 48.979591369628906, val_acc: 52.380950927734375\n",
            "Epoch: 67, train_loss: 0.43331532677014667, train_acc: 82.52577718098958, test_acc: 57.14285659790039, val_acc: 45.238094329833984\n",
            "Epoch: 68, train_loss: 0.48795561989148456, train_acc: 81.7313741048177, test_acc: 61.2244873046875, val_acc: 47.619049072265625\n",
            "Epoch: 69, train_loss: 0.3993912835915883, train_acc: 84.53282674153645, test_acc: 57.14285659790039, val_acc: 54.761905670166016\n",
            "Epoch: 70, train_loss: 0.35979970296223956, train_acc: 86.66087849934895, test_acc: 55.1020393371582, val_acc: 59.523807525634766\n",
            "Epoch: 71, train_loss: 0.535720020532608, train_acc: 80.2320073445638, test_acc: 55.1020393371582, val_acc: 50.0\n",
            "Epoch: 72, train_loss: 0.4761633773644765, train_acc: 81.17897542317708, test_acc: 46.93877410888672, val_acc: 50.0\n",
            "Epoch: 73, train_loss: 0.42523889740308124, train_acc: 84.90109252929688, test_acc: 53.06122589111328, val_acc: 50.0\n",
            "Epoch: 74, train_loss: 0.4612425963083903, train_acc: 84.01199340820312, test_acc: 61.2244873046875, val_acc: 50.0\n",
            "Epoch: 75, train_loss: 0.45791123310724896, train_acc: 82.06807454427083, test_acc: 55.1020393371582, val_acc: 54.761905670166016\n",
            "Epoch: 76, train_loss: 0.41225842634836835, train_acc: 83.78314208984375, test_acc: 55.1020393371582, val_acc: 54.761905670166016\n",
            "Epoch: 77, train_loss: 0.42125841975212097, train_acc: 82.74147542317708, test_acc: 59.18367385864258, val_acc: 54.761905670166016\n",
            "Epoch: 78, train_loss: 0.41400453448295593, train_acc: 82.81775919596355, test_acc: 59.18367385864258, val_acc: 57.14285659790039\n",
            "Epoch: 79, train_loss: 0.42976460854212445, train_acc: 81.88394165039062, test_acc: 57.14285659790039, val_acc: 64.28571319580078\n",
            "Epoch: 80, train_loss: 0.42362860838572186, train_acc: 81.96022542317708, test_acc: 61.2244873046875, val_acc: 61.904762268066406\n",
            "Epoch: 81, train_loss: 0.4481518069903056, train_acc: 81.69980875651042, test_acc: 57.14285659790039, val_acc: 61.904762268066406\n",
            "Epoch: 82, train_loss: 0.4006605346997579, train_acc: 86.69244384765625, test_acc: 61.2244873046875, val_acc: 57.14285659790039\n",
            "Epoch: 83, train_loss: 0.41482285658518475, train_acc: 86.1531982421875, test_acc: 57.14285659790039, val_acc: 61.904762268066406\n",
            "Epoch: 84, train_loss: 0.4074409306049347, train_acc: 82.74147542317708, test_acc: 55.1020393371582, val_acc: 57.14285659790039\n",
            "Epoch: 85, train_loss: 0.3658968408902486, train_acc: 85.60605875651042, test_acc: 57.14285659790039, val_acc: 52.380950927734375\n",
            "Epoch: 86, train_loss: 0.37252192695935565, train_acc: 86.24789428710938, test_acc: 57.14285659790039, val_acc: 57.14285659790039\n",
            "Epoch: 87, train_loss: 0.371634562810262, train_acc: 87.02914428710938, test_acc: 53.06122589111328, val_acc: 59.523807525634766\n",
            "Epoch: 88, train_loss: 0.3908354143301646, train_acc: 85.75862630208333, test_acc: 57.14285659790039, val_acc: 52.380950927734375\n",
            "Epoch: 89, train_loss: 0.3725363810857137, train_acc: 84.34869384765625, test_acc: 59.18367385864258, val_acc: 52.380950927734375\n",
            "Epoch: 90, train_loss: 0.38302111625671387, train_acc: 85.46664428710938, test_acc: 53.06122589111328, val_acc: 59.523807525634766\n",
            "Epoch: 91, train_loss: 0.37745700279871625, train_acc: 84.76167805989583, test_acc: 55.1020393371582, val_acc: 52.380950927734375\n",
            "Epoch: 92, train_loss: 0.3246881365776062, train_acc: 86.50831095377605, test_acc: 53.06122589111328, val_acc: 59.523807525634766\n",
            "Epoch: 93, train_loss: 0.40219279130299884, train_acc: 85.17466227213542, test_acc: 57.14285659790039, val_acc: 64.28571319580078\n",
            "Epoch: 94, train_loss: 0.34073297182718915, train_acc: 85.65077718098958, test_acc: 61.2244873046875, val_acc: 45.238094329833984\n",
            "Epoch: 95, train_loss: 0.38489533464113873, train_acc: 83.04661051432292, test_acc: 53.06122589111328, val_acc: 45.238094329833984\n",
            "Epoch: 96, train_loss: 0.35874078671137494, train_acc: 85.75862630208333, test_acc: 57.14285659790039, val_acc: 47.619049072265625\n",
            "Epoch: 97, train_loss: 0.40362364053726196, train_acc: 85.16150919596355, test_acc: 48.979591369628906, val_acc: 50.0\n",
            "Epoch: 98, train_loss: 0.4277810951073964, train_acc: 82.55734252929688, test_acc: 55.1020393371582, val_acc: 54.761905670166016\n",
            "Epoch: 99, train_loss: 0.35430554548899335, train_acc: 85.6192118326823, test_acc: 57.14285659790039, val_acc: 54.761905670166016\n",
            "Epoch: 100, train_loss: 0.3921799163023631, train_acc: 84.2724100748698, test_acc: 48.979591369628906, val_acc: 47.619049072265625\n",
            "Epoch: 101, train_loss: 0.35445337494214374, train_acc: 87.81039428710938, test_acc: 55.1020393371582, val_acc: 61.904762268066406\n",
            "Epoch: 102, train_loss: 0.40296535690625507, train_acc: 84.11984252929688, test_acc: 51.020408630371094, val_acc: 57.14285659790039\n",
            "Epoch: 103, train_loss: 0.3836107850074768, train_acc: 84.04355875651042, test_acc: 46.93877410888672, val_acc: 57.14285659790039\n",
            "Epoch: 104, train_loss: 0.3536064128081004, train_acc: 85.4219258626302, test_acc: 55.1020393371582, val_acc: 61.904762268066406\n",
            "Epoch: 105, train_loss: 0.3819724718729655, train_acc: 84.56439208984375, test_acc: 51.020408630371094, val_acc: 52.380950927734375\n",
            "Epoch: 106, train_loss: 0.2716892460982005, train_acc: 89.04934692382812, test_acc: 55.1020393371582, val_acc: 57.14285659790039\n",
            "Epoch: 107, train_loss: 0.3540240228176117, train_acc: 85.72706095377605, test_acc: 61.2244873046875, val_acc: 52.380950927734375\n",
            "Epoch: 108, train_loss: 0.3449734350045522, train_acc: 86.80029296875, test_acc: 51.020408630371094, val_acc: 54.761905670166016\n",
            "Epoch: 109, train_loss: 0.3201555808385213, train_acc: 86.69244384765625, test_acc: 51.020408630371094, val_acc: 64.28571319580078\n",
            "Epoch: 110, train_loss: 0.4067753354708354, train_acc: 83.8594258626302, test_acc: 46.93877410888672, val_acc: 57.14285659790039\n",
            "Epoch: 111, train_loss: 0.44227532545725506, train_acc: 84.45654296875, test_acc: 67.34693908691406, val_acc: 54.761905670166016\n",
            "Epoch: 112, train_loss: 0.3731133242448171, train_acc: 84.6722412109375, test_acc: 61.2244873046875, val_acc: 57.14285659790039\n",
            "Epoch: 113, train_loss: 0.34535661339759827, train_acc: 87.32112630208333, test_acc: 61.2244873046875, val_acc: 52.380950927734375\n",
            "Epoch: 114, train_loss: 0.4325941602389018, train_acc: 83.04661051432292, test_acc: 55.1020393371582, val_acc: 54.761905670166016\n",
            "Epoch: 115, train_loss: 0.33315115173657733, train_acc: 88.25494384765625, test_acc: 53.06122589111328, val_acc: 59.523807525634766\n",
            "Epoch: 116, train_loss: 0.4753753145535787, train_acc: 80.46085611979167, test_acc: 65.30612182617188, val_acc: 66.66666412353516\n",
            "Epoch: 117, train_loss: 0.4197166363398234, train_acc: 84.60911051432292, test_acc: 59.18367385864258, val_acc: 64.28571319580078\n",
            "Epoch: 118, train_loss: 0.44026370843251544, train_acc: 83.00189208984375, test_acc: 46.93877410888672, val_acc: 54.761905670166016\n",
            "Epoch: 119, train_loss: 0.41189951697985333, train_acc: 83.24915822347005, test_acc: 59.18367385864258, val_acc: 50.0\n",
            "Epoch: 120, train_loss: 0.372749388217926, train_acc: 83.96727498372395, test_acc: 63.26530456542969, val_acc: 52.380950927734375\n",
            "Epoch: 121, train_loss: 0.4220802088578542, train_acc: 82.89404296875, test_acc: 55.1020393371582, val_acc: 45.238094329833984\n",
            "Epoch: 122, train_loss: 0.3488217890262604, train_acc: 84.45654296875, test_acc: 65.30612182617188, val_acc: 57.14285659790039\n",
            "Epoch: 123, train_loss: 0.4261798659960429, train_acc: 83.75157674153645, test_acc: 48.979591369628906, val_acc: 54.761905670166016\n",
            "Epoch: 124, train_loss: 0.35882758100827533, train_acc: 87.10542805989583, test_acc: 59.18367385864258, val_acc: 64.28571319580078\n",
            "Epoch: 125, train_loss: 0.3934761385122935, train_acc: 85.19307454427083, test_acc: 40.81632614135742, val_acc: 64.28571319580078\n",
            "Epoch: 126, train_loss: 0.3212254047393799, train_acc: 89.08091227213542, test_acc: 61.2244873046875, val_acc: 50.0\n",
            "Epoch: 127, train_loss: 0.2957132160663605, train_acc: 88.10237630208333, test_acc: 55.1020393371582, val_acc: 61.904762268066406\n",
            "Epoch: 128, train_loss: 0.3806632657845815, train_acc: 85.09837849934895, test_acc: 51.020408630371094, val_acc: 57.14285659790039\n",
            "Epoch: 129, train_loss: 0.38226566712061566, train_acc: 86.17161051432292, test_acc: 46.93877410888672, val_acc: 61.904762268066406\n",
            "Epoch: 130, train_loss: 0.3687507013479869, train_acc: 84.04355875651042, test_acc: 65.30612182617188, val_acc: 59.523807525634766\n",
            "Epoch: 131, train_loss: 0.3371143341064453, train_acc: 86.43202718098958, test_acc: 59.18367385864258, val_acc: 47.619049072265625\n",
            "Epoch: 132, train_loss: 0.3654005825519562, train_acc: 84.45654296875, test_acc: 61.2244873046875, val_acc: 52.380950927734375\n",
            "Epoch: 133, train_loss: 0.3408743441104889, train_acc: 88.3312276204427, test_acc: 57.14285659790039, val_acc: 59.523807525634766\n",
            "Epoch: 134, train_loss: 0.3375041087468465, train_acc: 84.30397542317708, test_acc: 55.1020393371582, val_acc: 45.238094329833984\n",
            "Epoch: 135, train_loss: 0.42625345786412555, train_acc: 83.55429077148438, test_acc: 51.020408630371094, val_acc: 42.85714340209961\n",
            "Epoch: 136, train_loss: 0.31147878368695575, train_acc: 87.65782674153645, test_acc: 48.979591369628906, val_acc: 54.761905670166016\n",
            "Epoch: 137, train_loss: 0.3520015875498454, train_acc: 85.91119384765625, test_acc: 55.1020393371582, val_acc: 61.904762268066406\n",
            "Epoch: 138, train_loss: 0.32421186566352844, train_acc: 89.08091227213542, test_acc: 63.26530456542969, val_acc: 52.380950927734375\n",
            "Epoch: 139, train_loss: 0.2813972334067027, train_acc: 88.45222981770833, test_acc: 61.2244873046875, val_acc: 50.0\n",
            "Epoch: 140, train_loss: 0.3959318995475769, train_acc: 82.66519165039062, test_acc: 63.26530456542969, val_acc: 52.380950927734375\n",
            "Epoch: 141, train_loss: 0.3576844036579132, train_acc: 86.53987630208333, test_acc: 59.18367385864258, val_acc: 54.761905670166016\n",
            "Epoch: 142, train_loss: 0.42849816878636676, train_acc: 83.38331095377605, test_acc: 55.1020393371582, val_acc: 57.14285659790039\n",
            "Epoch: 143, train_loss: 0.32315418124198914, train_acc: 86.50831095377605, test_acc: 61.2244873046875, val_acc: 54.761905670166016\n",
            "Epoch: 144, train_loss: 0.3155515392621358, train_acc: 88.07081095377605, test_acc: 42.85714340209961, val_acc: 50.0\n",
            "Epoch: 145, train_loss: 0.4092339773972829, train_acc: 83.96727498372395, test_acc: 65.30612182617188, val_acc: 50.0\n",
            "Epoch: 146, train_loss: 0.27888859808444977, train_acc: 90.41456095377605, test_acc: 51.020408630371094, val_acc: 64.28571319580078\n",
            "Epoch: 147, train_loss: 0.2868235607941945, train_acc: 89.18876139322917, test_acc: 63.26530456542969, val_acc: 61.904762268066406\n",
            "Epoch: 148, train_loss: 0.36241306861241657, train_acc: 85.00894165039062, test_acc: 61.2244873046875, val_acc: 52.380950927734375\n",
            "Epoch: 149, train_loss: 0.3119711180528005, train_acc: 87.51841227213542, test_acc: 57.14285659790039, val_acc: 57.14285659790039\n"
          ]
        }
      ],
      "source": [
        "train_loss_arr, train_acc_arr, test_acc_arr, val_acc_arr = [], [], [], []\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "\n",
        "epochs = 150\n",
        "for epoch in range(epochs):\n",
        "    top1_train_accuracy = 0\n",
        "    train_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        logits = model(x_batch)\n",
        "        loss = criterion(logits, y_batch)\n",
        "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "        top1_train_accuracy += top1[0].item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss_arr.append(train_loss / len(train_loader))\n",
        "    train_acc_arr.append(top1_train_accuracy / len(train_loader))\n",
        "\n",
        "\n",
        "    top1_accuracy = 0\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        logits = model(x_batch)\n",
        "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "        top1_accuracy += top1[0].item()\n",
        "    test_acc_arr.append(top1_accuracy / len(test_loader))\n",
        "\n",
        "    top1_accuracy = 0\n",
        "    for x_batch, y_batch in val_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        logits = model(x_batch)\n",
        "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "        top1_accuracy += top1[0].item()\n",
        "    val_acc_arr.append(top1_accuracy / len(val_loader))\n",
        "\n",
        "    print(f\"Epoch: {epoch}, train_loss: {train_loss_arr[-1]}, train_acc: {train_acc_arr[-1]}, test_acc: {test_acc_arr[-1]}, val_acc: {val_acc_arr[-1]}\")\n",
        "\n",
        "root_path = \"./csv\"\n",
        "name = config.name\n",
        "if not os.path.exists(root_path):\n",
        "    os.makedirs(root_path)\n",
        "    \n",
        "with open(f\"{root_path}/{name}.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"train_loss\", \"train_acc\", \"test_acc\", \"val_acc\"])\n",
        "    for i in range(len(train_loss_arr)):\n",
        "        writer.writerow([train_loss_arr[i], train_acc_arr[i], test_acc_arr[i], val_acc_arr[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtYqHZirMNZk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "149b9ce8fb68473a837a77431c12281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a88c31d74f5c40a2b24bcff5a35d216c",
              "IPY_MODEL_60c6150177694717a622936b830427b5"
            ],
            "layout": "IPY_MODEL_88cd3db2831e4c13a4a634709700d6b2"
          }
        },
        "5901c2829a554c8ebbd5926610088041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c6150177694717a622936b830427b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f82234388e4701a02a9f68a177193a",
            "placeholder": "​",
            "style": "IPY_MODEL_957362a11d174407979cf17012bf9208",
            "value": " 2640404480/? [00:51&lt;00:00, 32685718.58it/s]"
          }
        },
        "88cd3db2831e4c13a4a634709700d6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957362a11d174407979cf17012bf9208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f82234388e4701a02a9f68a177193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88c31d74f5c40a2b24bcff5a35d216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5901c2829a554c8ebbd5926610088041",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dba019efadee4fdc8c799f309b9a7e70",
            "value": 1
          }
        },
        "dba019efadee4fdc8c799f309b9a7e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
