{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "PLOT_SIZE = (10, 6)\n",
    "\n",
    "def read_mlflow_csv(csv_path):\n",
    "    # headers: run_id,key,value,step,timestamp\n",
    "    # we are only interested in: acc_top1, acc_top1_train, acc_top1_val for each step (epoch)\n",
    "\n",
    "    acc_top1_arr, acc_top1_train_arr, acc_top1_val_arr = [], [], []\n",
    "    loss_l_arr, loss_u_arr = [], []\n",
    "    with open(csv_path, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            if row[1].strip() == 'acc_top1':\n",
    "                acc_top1_arr.append(float(row[2]))\n",
    "            elif row[1].strip() == 'acc_top1_train':\n",
    "                acc_top1_train_arr.append(float(row[2]))\n",
    "            elif row[1].strip() == 'acc_top1_val':\n",
    "                acc_top1_val_arr.append(float(row[2]))\n",
    "            elif row[1].strip() == 'losses_l_train':\n",
    "                loss_l_arr.append(float(row[2]))\n",
    "            elif row[1].strip() == 'losses_u_train':\n",
    "                loss_u_arr.append(float(row[2]))\n",
    "\n",
    "    return acc_top1_train_arr, acc_top1_val_arr, acc_top1_arr, loss_l_arr, loss_u_arr\n",
    "\n",
    "def read_tensorboard_csvs(csv_paths):\n",
    "    # headers: Wall time, Step, Value\n",
    "    csv_path_arr = csv_paths.split(\";\")\n",
    "    acc_arr_arr = []\n",
    "    for csv_path in csv_path_arr:\n",
    "        acc_top1_arr = []\n",
    "        with open(csv_path, 'r') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            next(csv_reader)\n",
    "            for row in csv_reader:\n",
    "                acc_top1_arr.append(float(row[2]))\n",
    "        acc_arr_arr.append(acc_top1_arr)\n",
    "    return acc_arr_arr\n",
    "\n",
    "def read_csv(csv_path):\n",
    "    with open(csv_path, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        train_acc_arr, val_acc_arr, test_acc_arr, train_loss_arr = [], [], [], []\n",
    "        for row in csv_reader:\n",
    "            if len(row) < 4:\n",
    "                break\n",
    "            train_loss_arr.append(float(row[0]))\n",
    "            train_acc_arr.append(float(row[1]))\n",
    "            test_acc_arr.append(float(row[2]))\n",
    "            val_acc_arr.append(float(row[3]))\n",
    "\n",
    "    if max(train_acc_arr) < 2:\n",
    "        train_acc_arr = [acc * 100 for acc in train_acc_arr]\n",
    "        test_acc_arr = [acc * 100 for acc in test_acc_arr]\n",
    "        val_acc_arr = [acc * 100 for acc in val_acc_arr]\n",
    "    return train_acc_arr, val_acc_arr, test_acc_arr, train_loss_arr\n",
    "\n",
    "def plot_train_val_test_mlflow(title, csv_path, save_path):\n",
    "    train_acc_arr, val_acc_arr, test_acc_arr, loss_l_arr, loss_u_arr = read_mlflow_csv(csv_path)\n",
    "    epochs = np.arange(1, len(train_acc_arr) + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=PLOT_SIZE)\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.plot(epochs, train_acc_arr, color='tab:blue', label='Training Accuracy')\n",
    "    ax1.plot(epochs, val_acc_arr, color='tab:green', label='Validation Accuracy')\n",
    "    ax1.plot(epochs, test_acc_arr, color='tab:orange', label='Test Accuracy')\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    plt.legend(lines, labels, loc='upper left')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=PLOT_SIZE)\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Unlabeled Loss')\n",
    "    ax1.plot(epochs, loss_u_arr, color=\"tab:orange\", label='Unlabeled Loss')\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Labeled Loss')\n",
    "    ax2.plot(epochs, loss_l_arr, color='tab:blue', label='Labeled Loss')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    plt.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.savefig(f\"{save_path}_loss.png\")\n",
    "    plt.close()\n",
    "    return plt\n",
    "\n",
    "\n",
    "def plot_train_val_test_tensorboard(titles, csv_path, save_path):\n",
    "    acc_arr_arr = read_tensorboard_csvs(csv_path)\n",
    "    title_arr = titles.split(\";\")\n",
    "    epochs = np.arange(1, len(acc_arr_arr[0]) + 1) * 300 / 1000\n",
    "    fig, ax1 = plt.subplots(figsize=PLOT_SIZE)\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    for title, acc_arr in zip(title_arr, acc_arr_arr):\n",
    "        ax1.plot(epochs, acc_arr, label=title)\n",
    "\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    plt.legend(lines, labels, loc='lower right')\n",
    "    plt.title(\"SimCLR Contrastive Learning\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    return plt\n",
    "\n",
    "def plot_train_val_test(title, csv_path, save_path):\n",
    "    if is_tensorboard(csv_path):\n",
    "        return plot_train_val_test_tensorboard(title, csv_path, save_path)\n",
    "    if is_mlflow(csv_path):\n",
    "        return plot_train_val_test_mlflow(title, csv_path, save_path)\n",
    "    train_acc_arr, val_acc_arr, test_acc_arr, train_loss_arr = read_csv(csv_path)\n",
    "    epochs = np.arange(1, len(train_loss_arr) + 1)\n",
    "    fig, ax1 = plt.subplots(figsize=PLOT_SIZE)\n",
    "    # change the font size to 12 for all elements on the plot\n",
    "\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.plot(epochs, train_acc_arr, color='tab:blue', label='Training Accuracy')\n",
    "    ax1.plot(epochs, val_acc_arr, color='tab:green', label='Validation Accuracy')\n",
    "    ax1.plot(epochs, test_acc_arr, color='tab:orange', label='Test Accuracy')\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Loss', color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.plot(epochs, train_loss_arr, color=color, label='Training Loss')\n",
    "\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    plt.legend(lines + lines2, labels + labels2, loc='lower left')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    return plt\n",
    "\n",
    "def is_mlflow(csv_path):\n",
    "    with open(csv_path, 'r') as csv_file:\n",
    "        first_line = csv_file.readline()\n",
    "        if \"run_id,key,value,step,timestamp\" == first_line.replace(\"\\n\", \"\").replace(\" \", \"\"):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "def is_tensorboard(csv_path):\n",
    "    return \";\" in csv_path\n",
    "    \n",
    "def get_best_val_test_acc(csv_path):\n",
    "    if is_tensorboard(csv_path):\n",
    "        return -1, -1, -1, -1\n",
    "    train_acc_arr, val_acc_arr, test_acc_arr, _ = read_csv(csv_path) if not is_mlflow(csv_path) else read_mlflow_csv(csv_path)[:4]\n",
    "    # if two val acc are the same with 0.001 precision, choose the one with higher test acc\n",
    "    best_val_acc = max(val_acc_arr)\n",
    "    best_val_acc_idxs = [i for i, val_acc in enumerate(val_acc_arr) if abs(val_acc - best_val_acc) < 0.001]\n",
    "\n",
    "    # get best test acc\n",
    "    best_test_acc = max([test_acc_arr[i] for i in best_val_acc_idxs])\n",
    "    best_test_acc_idx = [i for i in best_val_acc_idxs if test_acc_arr[i] == best_test_acc][-1]\n",
    "\n",
    "    # might as well get the best train acc\n",
    "    best_train_acc = train_acc_arr[best_test_acc_idx]\n",
    "    return best_train_acc, best_val_acc, best_test_acc, best_test_acc_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 (no pretraining, batch size 64)\t\tEpoch [38]: train acc[100.0000] val acc[54.7619] test acc[46.9388]\n",
      "ResNet18 (with pretraining, batch size 64)\t\tEpoch [20]: train acc[100.0000] val acc[47.6190] test acc[48.9796]\n",
      "SimCLR (ResNet18, dim 128, frozen)\t\tEpoch [61]: train acc[61.1322] val acc[57.1429] test acc[46.9388]\n",
      "SimCLR (ResNet18, dim 128, not frozen)\t\tEpoch [38]: train acc[77.9777] val acc[71.4286] test acc[61.2245]\n",
      "SimCLR (ResNet18, dim 256, frozen)\t\tEpoch [99]: train acc[63.1708] val acc[59.5238] test acc[55.1020]\n",
      "SimCLR (ResNet18, dim 256, not frozen)\t\tEpoch [65]: train acc[80.0610] val acc[69.0476] test acc[59.1837]\n",
      "SimCLR (ResNet50, dim 128, frozen)\t\tEpoch [112]: train acc[68.3475] val acc[66.6667] test acc[55.1020]\n",
      "SimCLR (ResNet50, dim 128, not frozen)\t\tEpoch [64]: train acc[86.0190] val acc[71.4286] test acc[55.1020]\n",
      "Vision Transformer (configuration 1)\t\tEpoch [46]: train acc[35.7746] val acc[34.6939] test acc[35.7143]\n",
      "Vision Transformer (configuration 2)\t\tEpoch [86]: train acc[46.1972] val acc[38.7755] test acc[35.7143]\n",
      "Vision Transformer (configuration 3)\t\tEpoch [155]: train acc[46.7606] val acc[40.8163] test acc[42.8571]\n",
      "MixMatch (default)\t\tEpoch [974]: train acc[85.4167] val acc[66.6667] test acc[65.3061]\n",
      "FixMatch (default)\t\tEpoch [628]: train acc[42.3611] val acc[42.8571] test acc[44.8980]\n",
      "FixMatch (big crop)\t\tEpoch [1686]: train acc[35.0694] val acc[42.8571] test acc[40.8163]\n",
      "MixMatch (big crop)\t\tEpoch [676]: train acc[81.9444] val acc[69.0476] test acc[71.4286]\n",
      "MixMatch (big crop, mu=50)\t\tEpoch [475]: train acc[75.0000] val acc[69.0476] test acc[59.1837]\n",
      "SimCLR (ResNet18, dim 128);SimCLR (ResNet18, dim 256);SimCLR (ResNet50, dim 128)\t\tEpoch [0]: train acc[-1.0000] val acc[-1.0000] test acc[-1.0000]\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "titles = {\n",
    "    \"./resnet/csv/resnet18_batch64_noaug_nopretrain.csv\": \"ResNet18 (no pretraining, batch size 64)\",\n",
    "    \"./resnet/csv/resnet18_batch64_noaug_pretrain.csv\": \"ResNet18 (with pretraining, batch size 64)\",\n",
    "    \"./simclr/feature_eval/csv/simclr_resnet18_dim128_batch256_epoch275_frozen.csv\": \"SimCLR (ResNet18, dim 128, frozen)\",\n",
    "    \"./simclr/feature_eval/csv/simclr_resnet18_dim128_batch256_epoch275_notfrozen.csv\": \"SimCLR (ResNet18, dim 128, not frozen)\",\n",
    "    \"./simclr/feature_eval/csv/simclr_resnet18_dim256_batch256_epoch275_frozen.csv\": \"SimCLR (ResNet18, dim 256, frozen)\",\n",
    "    \"./simclr/feature_eval/csv/simclr_resnet18_dim256_batch256_epoch275_notfrozen.csv\": \"SimCLR (ResNet18, dim 256, not frozen)\",\n",
    "    \"./simclr/feature_eval/csv/simclr_resnet50_dim128_batch200_epoch295_frozen.csv\": \"SimCLR (ResNet50, dim 128, frozen)\",\n",
    "    \"./simclr/feature_eval/csv/simclr_resnet50_dim128_batch200_epoch295_notfrozen.csv\": \"SimCLR (ResNet50, dim 128, not frozen)\",\n",
    "    \"./vision_transformer/train_acc.csv\": \"Vision Transformer (configuration 1)\",\n",
    "    \"./vision_transformer/train_acc_1.csv\": \"Vision Transformer (configuration 2)\",\n",
    "    \"./vision_transformer/train_acc_0.csv\": \"Vision Transformer (configuration 3)\",\n",
    "    \"./mixmatch_fixmatch/csv/mixmatch_orig.csv\": \"MixMatch (default)\",\n",
    "    \"./mixmatch_fixmatch/csv/fixmatch_orig.csv\": \"FixMatch (default)\",\n",
    "    \"./mixmatch_fixmatch/csv/fixmatch_bigcrop.csv\": \"FixMatch (big crop)\",\n",
    "    \"./mixmatch_fixmatch/csv/mixmatch_bigcrop.csv\": \"MixMatch (big crop)\",\n",
    "    \"./mixmatch_fixmatch/csv/mixmatch_bigcrop_mu50.csv\": \"MixMatch (big crop, mu=50)\",\n",
    "    \"./simclr/pretrain_csv/simclr_resnet18_outdim128.csv;./simclr/pretrain_csv/simclr_resnet18_outdim256.csv;./simclr/pretrain_csv/simclr_resnet50_outdim128.csv\": \"SimCLR (ResNet18, dim 128);SimCLR (ResNet18, dim 256);SimCLR (ResNet50, dim 128)\",\n",
    "}\n",
    "\n",
    "plot_dir = \"./plots/\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "for csv_path, title in titles.items():\n",
    "    save_path = plot_dir + title + \".png\"\n",
    "    plot_train_val_test(title, csv_path, save_path=save_path)\n",
    "    print(title + \"\\t\\t\", end=\"\")\n",
    "    best_train_acc, best_val_acc, best_test_acc, best_test_acc_idx = get_best_val_test_acc(csv_path)\n",
    "    print(f\"Epoch [{best_test_acc_idx + 1}]: train acc[{best_train_acc:.4f}] val acc[{best_val_acc:.4f}] test acc[{best_test_acc:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
